# frozen_string_literal: true

class Raif::ModelTools::<%= class_name %> < Raif::ModelTool
  # For example tool implementations, see: 
  # Wikipedia Search Tool: https://github.com/CultivateLabs/sentinel/blob/main/app/models/sentinel/model_tools/wikipedia_search.rb
  # Fetch URL Tool: https://github.com/CultivateLabs/sentinel/blob/main/app/models/sentinel/model_tools/fetch_url.rb

  # Define the argument schema the LLM should use when calling your tool.
  define_tool_arguments_schema do
    # string :title, description: "The title of the operation", minLength: 3
    #
    # object :settings, description: "Configuration settings" do
    #   boolean :enabled, description: "Whether the tool is enabled"
    #   integer :priority, description: "Priority level (1-10)", minimum: 1, maximum: 10
    #   array :tags, description: "Associated tags" do
    #     items type: "string"
    #   end
    # end
    #
    # array :products, description: "List of products" do
    #   object do
    #     integer :id, description: "Product identifier"
    #     string :name, description: "Product name"
    #     number :price, description: "Product price", minimum: 0
    #   end
    # end
  end

  # An example of how the LLM should invoke your tool. This should return a hash with name and arguments keys.
  # `to_json` will be called on it and provided to the LLM as an example of how to invoke your tool.
  def self.example_model_invocation
    {
      "name": tool_name,
      "arguments": { }
    }
  end

  def self.tool_description
    "Description of your tool that will be provided to the LLM so it knows when to invoke it"
  end

  # When your tool is invoked by the LLM in a Raif::Agent loop, 
  # the results of the tool invocation are provided back to the LLM as an observation.
  # This method should return whatever you want provided to the LLM.
  # For example, if you were implementing a GoogleSearch tool, this might return a JSON
  # object containing search results for the query.
  def self.observation_for_invocation(tool_invocation)
    return "No results found" unless tool_invocation.result.present?

    JSON.pretty_generate(tool_invocation.result)
  end

  # When your tool is invoked in a Raif::Conversation, should the result be automatically provided back to the model?
  # When true, observation_for_invocation will be used to produce the observation provided to the model
  def self.triggers_observation_to_model?
    false
  end

  # When the LLM invokes your tool, this method will be called with a `Raif::ModelToolInvocation` record as an argument.
  # It should handle the actual execution of the tool. 
  # For example, if you are implementing a GoogleSearch tool, this method should run the actual search
  # and store the results in the tool_invocation's result JSON column.
  def self.process_invocation(tool_invocation)
    # Extract arguments from tool_invocation.tool_arguments
    # query = tool_invocation.tool_arguments["query"]
    #
    # Process the invocation and perform the desired action
    # ...
    #
    # Store the results in the tool_invocation
    # tool_invocation.update!(
    #   result: {
    #     # Your result data structure
    #   }
    # )
    #
    # Return the result
    # tool_invocation.result
  end

end